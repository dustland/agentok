# conversable_agents.j2
{%- macro generate_conversable_agents(conversable_nodes) -%}

import tempfile
temp_dir = tempfile.gettempdir()

# Conversable Agents

{% for node in conversable_nodes %}
node_{{ node.id }} = {{ node.data.class_type }}(
    name="{{ node.data.name }}",
    {%- if node.data.description %}
    description="""{{ node.data.description }}""",
    {%- endif %}
    {%- if node.data.system_message %}
    system_message="""{{ node.data.system_message }}""",
    {%- endif %}
    {%- if node.data.max_consecutive_auto_reply %}
    max_consecutive_auto_reply={{ node.data.max_consecutive_auto_reply }},
    {%- endif %}
    {%- if node.data.termination_msg %}
    is_termination_msg=lambda msg: msg["content"] is not None and "{{ node['data']['termination_msg'] | lower }}" in msg["content"].lower(),
    {%- endif %}
    {%- if node.data.human_input_mode %}
    human_input_mode="{{ node.data.human_input_mode }}",
    {%- endif %}
    {%- if node.data.disable_llm %}
    llm_config=False,
    {%- else %}
    {%- if node.data.model_id %}
    llm_config={"config_list": autogen.filter_config(llm_config["config_list"], filter_dict={"model": ["{{ node.data.model_id }}"]})},
    {%- else %}
    llm_config=llm_config,
    {%- endif %}
    {%- endif %}
    {%- if node.data.enable_code_execution %}
    code_execution_config={"use_docker": False, "work_dir": temp_dir}, # Simplified setting for code execution
    {%- endif %}
)
{% endfor %}
{%- endmacro -%}